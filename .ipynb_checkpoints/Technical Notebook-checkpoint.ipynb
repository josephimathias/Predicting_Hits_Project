{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschool/anaconda3/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, f1_score, confusion_matrix, classification_report\n",
    "from sklearn import tree \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.externals.six import StringIO  \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, minmax_scale\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv('data/savant_data_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 89)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2019-09-29', '2019-09-28', '2019-09-27', '2019-09-26',\n",
       "       '2019-09-25', '2019-09-24', '2019-09-23', '2019-09-22',\n",
       "       '2019-09-21', '2019-09-20', '2019-09-19', '2019-09-18',\n",
       "       '2019-09-17', '2019-09-16', '2019-09-15', '2019-09-14',\n",
       "       '2019-09-13', '2019-09-12', '2019-09-11', '2019-09-10',\n",
       "       '2019-09-09', '2019-09-08', '2019-09-07', '2019-09-06',\n",
       "       '2019-09-05', '2019-09-04', '2019-09-03', '2019-09-02',\n",
       "       '2019-09-01', '2019-08-31', '2019-08-30', '2019-08-29',\n",
       "       '2019-08-28', '2019-08-27', '2019-08-26', '2019-08-25',\n",
       "       '2019-08-24', '2019-08-23', '2019-08-22', '2019-08-21',\n",
       "       '2019-08-20', '2019-08-19', '2019-08-18', '2019-08-17',\n",
       "       '2019-08-16', '2019-08-15', '2019-08-14', '2019-08-13',\n",
       "       '2019-08-12', '2019-08-11', '2019-08-10', '2019-08-09',\n",
       "       '2019-08-08', '2019-08-07', '2019-08-06', '2019-08-05',\n",
       "       '2019-08-04', '2019-08-03', '2019-08-02', '2019-08-01',\n",
       "       '2019-07-31', '2019-07-30', '2019-07-29', '2019-07-28',\n",
       "       '2019-07-27', '2019-07-26', '2019-07-25', '2019-07-24',\n",
       "       '2019-07-23', '2019-07-22', '2019-07-21', '2019-07-20',\n",
       "       '2019-07-19', '2019-07-18', '2019-07-17', '2019-07-16',\n",
       "       '2019-07-15', '2019-07-14', '2019-07-13', '2019-07-12',\n",
       "       '2019-07-11', '2019-07-07', '2019-07-06', '2019-07-05',\n",
       "       '2019-07-04', '2019-07-03', '2019-07-02', '2019-07-01',\n",
       "       '2019-06-30', '2019-06-29', '2019-06-28', '2019-06-27',\n",
       "       '2019-06-26', '2019-06-25', '2019-06-24', '2019-06-23',\n",
       "       '2019-06-22', '2019-06-21', '2019-06-20', '2019-06-19',\n",
       "       '2019-06-18', '2019-06-17', '2019-06-16', '2019-06-15',\n",
       "       '2019-06-14', '2019-06-13', '2019-06-12', '2019-06-11',\n",
       "       '2019-06-10', '2019-06-09', '2019-06-08', '2019-06-07',\n",
       "       '2019-06-06', '2019-06-05', '2019-06-04', '2019-06-03',\n",
       "       '2019-06-02', '2019-06-01', '2019-05-31', '2019-05-30',\n",
       "       '2019-05-29', '2019-05-28', '2019-05-27', '2019-05-26',\n",
       "       '2019-05-25', '2019-05-24', '2019-05-23', '2019-05-22',\n",
       "       '2019-05-21', '2019-05-20', '2019-05-19', '2019-05-18',\n",
       "       '2019-05-17', '2019-05-16', '2019-05-15', '2019-05-14',\n",
       "       '2019-05-13', '2019-05-12', '2019-05-11', '2019-05-10',\n",
       "       '2019-05-09', '2019-05-08', '2019-05-07', '2019-05-06',\n",
       "       '2019-05-05', '2019-05-04', '2019-05-03', '2019-05-02',\n",
       "       '2019-05-01', '2019-04-30', '2019-04-29', '2019-04-28',\n",
       "       '2019-04-27', '2019-04-26', '2019-04-25', '2019-04-24',\n",
       "       '2019-04-23', '2019-04-22', '2019-04-21', '2019-04-20',\n",
       "       '2019-04-19', '2019-04-18', '2019-04-17', '2019-04-16',\n",
       "       '2019-04-15', '2019-04-14'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.game_date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pitch_type', 'game_date', 'release_speed', 'release_pos_x',\n",
       "       'release_pos_z', 'player_name', 'batter', 'pitcher', 'events',\n",
       "       'description', 'spin_dir', 'spin_rate_deprecated',\n",
       "       'break_angle_deprecated', 'break_length_deprecated', 'zone', 'des',\n",
       "       'game_type', 'stand', 'p_throws', 'home_team', 'away_team', 'type',\n",
       "       'hit_location', 'bb_type', 'balls', 'strikes', 'game_year', 'pfx_x',\n",
       "       'pfx_z', 'plate_x', 'plate_z', 'on_3b', 'on_2b', 'on_1b',\n",
       "       'outs_when_up', 'inning', 'inning_topbot', 'hc_x', 'hc_y',\n",
       "       'tfs_deprecated', 'tfs_zulu_deprecated', 'fielder_2', 'umpire', 'sv_id',\n",
       "       'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az', 'sz_top', 'sz_bot',\n",
       "       'hit_distance_sc', 'launch_speed', 'launch_angle', 'effective_speed',\n",
       "       'release_spin_rate', 'release_extension', 'game_pk', 'pitcher.1',\n",
       "       'fielder_2.1', 'fielder_3', 'fielder_4', 'fielder_5', 'fielder_6',\n",
       "       'fielder_7', 'fielder_8', 'fielder_9', 'release_pos_y',\n",
       "       'estimated_ba_using_speedangle', 'estimated_woba_using_speedangle',\n",
       "       'woba_value', 'woba_denom', 'babip_value', 'iso_value',\n",
       "       'launch_speed_angle', 'at_bat_number', 'pitch_number', 'pitch_name',\n",
       "       'home_score', 'away_score', 'bat_score', 'fld_score', 'post_away_score',\n",
       "       'post_home_score', 'post_bat_score', 'post_fld_score',\n",
       "       'if_fielding_alignment', 'of_fielding_alignment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create New Feature, Spray Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['spray_angle'] = ((df4['hc_x'] - 125.42) / (198.27 - df4['hc_y'])) * 180/math.pi*.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Groupings Graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df4, x=\"launch_speed\", y=\"launch_angle\", log_x=False, log_y = False,\n",
    "                 hover_name=\"player_name\", hover_data=None, color=\"events\", color_discrete_sequence=px.colors.qualitative.Set3, title=\"Balls in Play by Category\")\n",
    "fig.update_xaxes(title_text='Launch Speed')\n",
    "fig.update_yaxes(title_text='Launch Angle')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Features and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_rel = df4[['release_speed', 'release_pos_x',\n",
    "       'release_pos_z', 'player_name', 'batter', 'pitcher', 'events',\n",
    "       'zone',\n",
    "       'stand', 'p_throws', 'type',\n",
    "       'hit_location', 'balls', 'strikes', 'pfx_x',\n",
    "       'pfx_z', 'plate_x', 'plate_z',\n",
    "       'outs_when_up', 'inning', 'inning_topbot',\n",
    "       'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az', 'sz_top', 'sz_bot',\n",
    "       'hit_distance_sc', 'launch_speed', 'launch_angle', 'effective_speed',\n",
    "       'release_spin_rate', 'release_extension',  'release_pos_y',\n",
    "        'at_bat_number', 'pitch_number', 'pitch_name',\n",
    "       'if_fielding_alignment', 'of_fielding_alignment', 'spray_angle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_rel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_features_and_target = df4_rel[['release_speed', 'release_pos_x',\n",
    "       'release_pos_z', 'events',\n",
    "       'zone',\n",
    "       'stand', 'p_throws',\n",
    "        'balls', 'strikes', 'pfx_x',\n",
    "       'pfx_z', 'plate_x', 'plate_z',\n",
    "       'outs_when_up', 'inning', 'inning_topbot',\n",
    "       'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az', 'sz_top', 'sz_bot',\n",
    "     'launch_speed', 'launch_angle', 'effective_speed',\n",
    "       'release_spin_rate', 'release_extension',  'release_pos_y',\n",
    "     'at_bat_number', 'pitch_number', 'pitch_name',\n",
    "       'if_fielding_alignment', 'of_fielding_alignment', 'spray_angle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_features_and_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_features_and_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_features_and_target[df4_features_and_target.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_features_and_target_clean = df4_features_and_target.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_features_and_target_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_features_and_target_clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Into Features and Target, and Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df4_features_and_target_clean['events']\n",
    "\n",
    "X = df4_features_and_target_clean.drop(['events'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies = pd.get_dummies(X, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test , y_train, y_test = train_test_split(X_dummies, y, random_state = 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Vanilla Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test,y_pred)*100\n",
    "print(\"Accuracy is :{0}\".format(acc))\n",
    "# Check the AUC for predictions\n",
    "# Create and print a confusion matrix \n",
    "print('\\nConfusion Matrix')\n",
    "print('----------------')\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tree trained from complete dataset (optional)\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data, filled=True, rounded=True,special_characters=True, feature_names=X_train.columns)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [1, 2, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier()\n",
    "\n",
    "dt_grid_search = GridSearchCV(clf, param_grid, cv=3, return_train_score=True)\n",
    "dt_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_gs_training_score = np.mean(dt_grid_search.cv_results_['mean_train_score'])\n",
    "dt_gs_testing_score = dt_grid_search.score(X_train, y_train)\n",
    "\n",
    "print(f\"Mean Training Score: {dt_gs_training_score :.2%}\")\n",
    "print(f\"Mean Testing Score: {dt_gs_testing_score :.2%}\")\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Best Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split = 20)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test,y_pred) * 100\n",
    "print(\"Accuracy is :{0}\".format(acc))\n",
    "# Check the AUC for predictions\n",
    "# Create and print a confusion matrix \n",
    "print('\\nConfusion Matrix')\n",
    "print('----------------')\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Use SMOTE to Correct Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.value_counts()) #Previous original class distribution\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_sample(X_train, y_train) \n",
    "print(pd.Series(y_train_smote).value_counts()) #Preview synthetic sample class distributi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split = 20)\n",
    "clf.fit(X_train_smote, y_train_smote)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test,y_pred) * 100\n",
    "print(\"Accuracy is :{0}\".format(acc))\n",
    "# Check the AUC for predictions\n",
    "# Create and print a confusion matrix \n",
    "print('\\nConfusion Matrix')\n",
    "print('----------------')\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Use Scaler to Normalize Continuous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Training Data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data_train = scaler.fit_transform(X_train_smote)\n",
    "scaled_data_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split = 20)\n",
    "clf.fit(scaled_data_train, y_train_smote)\n",
    "y_pred = clf.predict(scaled_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test,y_pred) * 100\n",
    "print(\"Accuracy is :{0}\".format(acc))\n",
    "# Check the AUC for predictions\n",
    "# Create and print a confusion matrix \n",
    "print('\\nConfusion Matrix')\n",
    "print('----------------')\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_data_train = scaler.fit_transform(X_train_smote)\n",
    "scaled_data_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split = 20)\n",
    "clf.fit(scaled_data_train, y_train_smote)\n",
    "y_pred = clf.predict(scaled_data_test)\n",
    "training_pred = clf.predict(scaled_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test,y_pred) * 100\n",
    "acc2 = accuracy_score(y_train_smote, training_pred)*100\n",
    "print(\"Testing Accuracy is :{0}\".format(acc))\n",
    "print(\"Training Accuracy is :{0}\".format(acc2))\n",
    "# Check the AUC for predictions\n",
    "# Create and print a confusion matrix \n",
    "print('\\nConfusion Matrix')\n",
    "print('----------------')\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Plot Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure(figsize=(15,9))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train.columns.values) \n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    print(range(n_features))\n",
    "\n",
    "plot_feature_importances(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Small Tree for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(criterion='gini', max_depth=3, min_samples_split = 20)\n",
    "clf.fit(scaled_data_train, y_train_smote)\n",
    "y_pred = clf.predict(scaled_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test,y_pred) * 100\n",
    "print(\"Accuracy is :{0}\".format(acc))\n",
    "# Check the AUC for predictions\n",
    "# Create and print a confusion matrix \n",
    "print('\\nConfusion Matrix')\n",
    "print('----------------')\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tree trained from complete dataset (optional)\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data, filled=True, rounded=True,special_characters=True, feature_names=X_train.columns, rotate=True, )\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, max_depth= 5)\n",
    "forest.fit(scaled_data_train, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forest.score(scaled_data_train, y_train_smote))\n",
    "print(forest.score(scaled_data_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_feature_importances(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nConfusion Matrix')\n",
    "print('----------------')\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest=RandomForestClassifier()\n",
    "\n",
    "rf_grid_search = GridSearchCV(forest, param_grid, cv=3, return_train_score=True)\n",
    "rf_grid_search.fit(scaled_data_train, y_train_smote)\n",
    "\n",
    "rf_gs_training_score = np.mean(dt_grid_search.cv_results_['mean_train_score'])\n",
    "rf_gs_testing_score = dt_grid_search.score(scaled_data_train, y_train_smote)\n",
    "\n",
    "print(f\"Mean Training Score: {dt_gs_training_score :.2%}\")\n",
    "print(f\"Mean Testing Score: {dt_gs_testing_score :.2%}\")\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, max_depth= 10, min_samples_split=5, criterion='entropy')\n",
    "forest.fit(scaled_data_train, y_train_smote)\n",
    "print(forest.score(scaled_data_train, y_train_smote))\n",
    "print(forest.score(scaled_data_test, y_test))\n",
    "plot_feature_importances(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, importance in zip(X_train.columns, forest.feature_importances_):\n",
    "    print(name, \"=\", importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf1.fit(scaled_data_train, y_train_smote)\n",
    "test_preds = clf1.predict(scaled_data_test)\n",
    "train_preds = clf1.predict(scaled_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(labels, preds):\n",
    "    print(\"Accuracy Score: {}\".format(accuracy_score(labels, preds)))\n",
    "    \n",
    "print_metrics(y_test, test_preds)\n",
    "print_metrics(y_train_smote, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nConfusion Matrix')\n",
    "print('----------------')\n",
    "print(pd.crosstab(y_test, test_preds, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k(X_train, y_train, X_test, y_test, min_k=1, max_k=7):\n",
    "    best_k = 0\n",
    "    best_score = 0.0\n",
    "    for k in range(min_k, max_k+1, 2):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        preds = knn.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        if acc > best_score:\n",
    "            best_k = k\n",
    "            best_score = acc\n",
    "    \n",
    "    print(\"Best Value for k: {}\".format(best_k))\n",
    "    print(\"Accuracy Score: {}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_k(scaled_data_train, y_train_smote, scaled_data_test, y_test, min_k=1, max_k=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_k(scaled_data_train, y_train_smote, scaled_data_test, y_test, min_k=11, max_k=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbt_clf.fit(scaled_data_train, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_clf_scaled_train_preds = gbt_clf.predict(scaled_data_train)\n",
    "gbt_clf_scaled_test_preds = gbt_clf.predict(scaled_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_acc(true, preds, model_name):\n",
    "    acc = accuracy_score(true, preds)\n",
    "#     f1 = f1_score(true, preds)\n",
    "    print(\"Model: {}\".format(model_name))\n",
    "    print(\"Accuracy: {}\".format(acc))\n",
    "#     print(\"F1-Score: {}\".format(f1))\n",
    "    \n",
    "print(\"Training Metrics\")\n",
    "display_acc(y_train_smote, gbt_clf_scaled_train_preds, model_name='Gradient Boosted Trees')\n",
    "print(\"\")\n",
    "print(\"Testing Metrics\")\n",
    "display_acc(y_test, gbt_clf_scaled_test_preds, model_name='Gradient Boosted Trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_feature_importances(gbt_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(scaled_data_train, y_train_smote)\n",
    "training_preds = clf.predict(scaled_data_train)\n",
    "val_preds = clf.predict(scaled_data_test)\n",
    "training_accuracy = accuracy_score(y_train_smote, training_preds)\n",
    "val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\": [0.1],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_child_weight': [10],\n",
    "    'subsample': [ 0.7],\n",
    "    'n_estimators': [100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_clf = GridSearchCV(clf, param_grid, scoring='accuracy', cv=5, n_jobs=1)\n",
    "# grid_clf.fit(scaled_data_train, y_train_smote)\n",
    "\n",
    "# best_parameters = grid_clf.best_params_\n",
    "\n",
    "# print(\"Grid Search found the following optimal parameters: \")\n",
    "# for param_name in sorted(best_parameters.keys()):\n",
    "#     print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# training_preds = grid_clf.predict(scaled_data_train)\n",
    "# val_preds = grid_clf.predict(scaled_data_test)\n",
    "# training_accuracy = accuracy_score(y_train_smote, training_preds)\n",
    "# val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "# print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('\\nConfusion Matrix')\n",
    "print('----------------')\n",
    "print(pd.crosstab(y_test, val_preds, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nConfusion Matrix')\n",
    "print('----------------')\n",
    "print(pd.crosstab(y_test, val_preds, rownames=['True'], colnames=['Predicted'], margins=True, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['y_pred'] = val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['y_test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_viz_df = X_test[['y_pred', 'y_test', 'launch_angle', 'launch_speed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_viz_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_viz_df[\"correct\"] = np.where(X_test_viz_df.y_pred == X_test_viz_df.y_test, 'True', 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"images\"):\n",
    "    os.mkdir(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(X_test_viz_df[:], x=\"launch_speed\", y=\"launch_angle\", log_x=False, log_y = False, hover_name=\"y_test\",\n",
    "                hover_data = ['y_pred'], color=\"correct\", title=\"Test Errors\", color_discrete_map={\"True\": \"#009F0D\", \"False\":\"#FFC93F\"})\n",
    "fig.update_xaxes(title_text='Launch Speed')\n",
    "fig.update_yaxes(title_text='Launch Angle')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(X_test_viz_df.loc[X_test_viz_df['y_test'] == 'triple'], x=\"launch_speed\", y=\"launch_angle\", log_x=False, log_y = False, hover_name=\"y_test\",\n",
    "                hover_data = ['y_pred'], color=\"correct\", title=\"True Triples\", color_discrete_map={\"True\": \"#009F0D\", \"False\":\"#FFC93F\"})\n",
    "fig.update_xaxes(title_text='Launch Speed')\n",
    "fig.update_yaxes(title_text='Launch Angle')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = ['single',  'double',  'triple',  'home_run',  'sac_bunt',  'sac_fly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                         normalize=False,\n",
    "                         title=None,\n",
    "                         cmap=plt.cm.summer):\n",
    "   \"\"\"\n",
    "   This function prints and plots the confusion matrix.\n",
    "   Normalization can be applied by setting normalize=True.\n",
    "   \"\"\"\n",
    "   if not title:\n",
    "       if normalize:\n",
    "           title = 'Normalized confusion matrix'\n",
    "       else:\n",
    "           title = 'Confusion matrix, without normalization'\n",
    "   # Compute confusion matrix\n",
    "   cm = confusion_matrix(y_true, y_pred, labels=events)\n",
    "   # Only use the labels that appear in the data\n",
    "   if normalize:\n",
    "       cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "       print(\"Normalized confusion matrix\")\n",
    "   else:\n",
    "       print('Confusion matrix, without normalization')\n",
    "   print(cm)\n",
    "   fig, ax = plt.subplots()\n",
    "   im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "   # We want to show all ticks...\n",
    "   ax.set(xticks=np.arange(cm.shape[1]),\n",
    "          yticks=np.arange(cm.shape[0]),\n",
    "          # ... and label them with the respective list entries\n",
    "          xticklabels=classes, yticklabels=classes,\n",
    "          title=title,\n",
    "          ylabel='True label',\n",
    "          xlabel='Predicted label')\n",
    "   # Rotate the tick labels and set their alignment.\n",
    "   plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "            rotation_mode=\"anchor\")\n",
    "   # Loop over data dimensions and create text annotations.\n",
    "   fmt = '.2f' if normalize else 'd'\n",
    "   thresh = cm.max() / 2.\n",
    "   for i in range(cm.shape[0]):\n",
    "       for j in range(cm.shape[1]):\n",
    "           ax.text(j, i, format(cm[i, j], fmt),\n",
    "                   ha=\"center\", va=\"center\",\n",
    "                   color=\"black\" if cm[i, j] > thresh else \"white\")\n",
    "   fig.tight_layout()\n",
    "   return ax\n",
    "np.set_printoptions(precision=2)\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, val_preds, classes=events,\n",
    "                     title='Confusion matrix, without normalization')\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, val_preds, classes=events, normalize=True,\n",
    "                     title='Normalized confusion matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
